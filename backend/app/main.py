from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, Optional
import asyncio, json
import numpy as np

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£/ç’°å¢ƒ/MARL/ãƒ¡ãƒˆãƒªã‚¯ã‚¹
from .utils import make_id
from .env import SwarmEnv
from .marl import MADDPGSystem
from .metrics import coverage_m1, uniformity_m2

# LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from .llm.router import router as llm_router
from .llm.client import generate_prior_reward_dsl
from .llm.dsl_runtime import build_prior_fn, build_reward_fn

app = FastAPI(title="LAMARL Backend API", version="1.0.0")

# LLMãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ç™»éŒ²
app.include_router(llm_router)

# CORSè¨­å®šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:5174",  # Vite alternative port
        "http://localhost:3000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ã€ŒçŠ¶æ…‹ã€ã‚’ãƒ¡ãƒ¢ãƒªä¿æŒï¼ˆæœ¬ã‚¹ã‚³ãƒ¼ãƒ—ã§ã¯DBãƒ¬ã‚¹é‹ç”¨ï¼‰
EPISODES: Dict[str, dict] = {}

# ------- ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆPydanticï¼‰ -------

class EpisodeCreate(BaseModel):
    """
    ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆæ™‚ã®è¨­å®šã€‚
    å½¢çŠ¶ã‚„ãƒ­ãƒœãƒƒãƒˆæ•°ãªã©ã‚’å—ã‘å–ã‚Šã€ç’°å¢ƒã¨RLã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã€‚
    """
    shape: str = "circle"
    seed: int = 1234
    n_robot: int = 30
    r_sense: float = 0.4
    r_avoid: float = 0.1
    nhn: int = 6
    nhc: int = 80
    grid_size: int = 64
    l_cell: float = 1.0

class TrainStart(BaseModel):
    """
    å­¦ç¿’é–‹å§‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‚
    - episodes: ä½•ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å›ã™ã‹
    - episode_len: 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
    - use_llm: LLMç”Ÿæˆã®Prior/Rewardã‚’ä½¿ç”¨ã™ã‚‹ã‹
    - task_description: LLMç”Ÿæˆç”¨ã®ã‚¿ã‚¹ã‚¯è¨˜è¿°
    - llm_model: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
    """
    episode_id: str
    episodes: int = 1
    episode_len: int = 200
    use_llm: bool = False
    task_description: Optional[str] = None
    llm_model: str = "gemini-2.0-flash-exp"

# ------- åŸºæœ¬ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ -------

@app.get("/health")
def health():
    """ç¨¼åƒç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚"""
    return {"status": "ok"}

# ------- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆ -------

@app.post("/episodes")
def create_ep(cfg: EpisodeCreate):
    """
    ç’°å¢ƒã¨ MADDPG ã‚’åˆæœŸåŒ–ã—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰IDã‚’æ‰•ã„å‡ºã™ã€‚
    - å¹¾ä½•æ¡ä»¶ï¼ˆåå®¹å¯èƒ½æ€§ï¼‰ã‚‚ãƒã‚§ãƒƒã‚¯
    - ãƒ¡ãƒ¢ãƒªä¸Šã® EPISODES ã«ç™»éŒ²
    """
    ep_id = make_id("ep")

    # ç’°å¢ƒã‚’ä»®ä½œæˆã—ã¦ mask æƒ…å ±ï¼ˆã‚»ãƒ«æ•°ãªã©ï¼‰ã‚’ç¢ºèª
    env = SwarmEnv(shape=cfg.shape, grid_size=cfg.grid_size, n_robot=cfg.n_robot,
                   r_sense=cfg.r_sense, r_avoid=cfg.r_avoid, nhn=cfg.nhn, nhc=cfg.nhc,
                   l_cell=cfg.l_cell, seed=cfg.seed)
    n_cell = int((env.mask == 1).sum())

    # å¹¾ä½•æ¡ä»¶: 4 * n_robot * r_avoid^2 â‰¤ n_cell * l_cell^2
    if 4 * cfg.n_robot * (cfg.r_avoid**2) > n_cell * (cfg.l_cell**2):
        raise HTTPException(400, "Geometry condition not satisfied")

    # è¦³æ¸¬æ¬¡å…ƒã‚’æ¨å®šï¼ˆMADDPG ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆã«å¿…è¦ï¼‰
    obs0 = env.observe()
    obs_dim = obs0.shape[1]

    # MADDPGï¼ˆn_agents=ãƒ­ãƒœãƒƒãƒˆæ•°, å±€æ‰€Qï¼‰
    maddpg = MADDPGSystem(
        n_agents=cfg.n_robot, obs_dim=obs_dim,
        gamma=0.99, batch=512, lr_actor=1e-4, lr_critic=1e-3,
        noise=0.1, tau=0.005, capacity=1_000_000, warmup_steps=5000
    )

    # ãƒ¡ãƒ¢ãƒªã«ä¿æŒï¼ˆDBãƒ¬ã‚¹ï¼‰
    EPISODES[ep_id] = {
        "cfg": cfg,
        "env": env,
        "rl": maddpg,
        "metrics": {"timeline": []},  # SSEã§æµã™ã‚¤ãƒ™ãƒ³ãƒˆã‚’è“„ç©
        "should_stop": False,  # å­¦ç¿’åœæ­¢ãƒ•ãƒ©ã‚°
    }
    return {"episode_id": ep_id}

# ------- å­¦ç¿’é–‹å§‹ï¼ˆéåŒæœŸã‚¿ã‚¹ã‚¯èµ·å‹•ï¼‰ -------

@app.post("/train")
async def start_train(req: TrainStart):
    """
    å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ asyncio ã‚¿ã‚¹ã‚¯ã§èµ·å‹•ã€‚
    - ã“ã®APIã¯å³æ™‚ã« {started: true} ã‚’è¿”ã—ã€
      å®Ÿéš›ã®é€²æ—ã¯ /stream ã® SSE ã§å—ã‘å–ã‚‹ã€‚
    - use_llm=True ã®å ´åˆã€LLMç”Ÿæˆã®Prior/Rewardã‚’ä½¿ç”¨
    """
    if req.episode_id not in EPISODES:
        raise HTTPException(404, "episode not found")
    store = EPISODES[req.episode_id]
    store["episodes_total"] = req.episodes
    store["episode_len"] = req.episode_len
    store["should_stop"] = False  # åœæ­¢ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    store["metrics"]["timeline"].clear()  # å¤ã„ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚¯ãƒªã‚¢
    
    # LLMç”Ÿæˆã®Prior/Rewardè¨­å®š
    if req.use_llm:
        try:
            print(f"ğŸ¤– LLMç”Ÿæˆé–‹å§‹: model={req.llm_model}")
            cfg = store["cfg"]
            
            # ã‚¿ã‚¹ã‚¯è¨˜è¿°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”Ÿæˆ
            task_desc = req.task_description or f"{cfg.n_robot}å°ã®ãƒ­ãƒœãƒƒãƒˆã§{cfg.shape}å½¢çŠ¶ã‚’å½¢æˆã™ã‚‹"
            
            # LLMç”Ÿæˆ
            env_params = {
                "shape": cfg.shape,
                "n_robot": cfg.n_robot,
                "r_sense": cfg.r_sense,
                "r_avoid": cfg.r_avoid,
                "n_hn": cfg.nhn,
                "n_hc": cfg.nhc,
            }
            
            dsl = generate_prior_reward_dsl(
                task_description=task_desc,
                env_params=env_params,
                model=req.llm_model,
                temperature=0.7,
                use_cot=True,
                use_basic_apis=True
            )
            
            # DSLã‹ã‚‰å®Ÿè¡Œå¯èƒ½ãªé–¢æ•°ã‚’æ§‹ç¯‰
            prior_fn = build_prior_fn(dsl["prior"])
            reward_fn = build_reward_fn(dsl["reward"])
            
            # MADDPGSystemã«è¨­å®š
            maddpg: MADDPGSystem = store["rl"]
            maddpg.set_prior_policy(prior_fn)
            maddpg.set_reward_function(reward_fn)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            store["llm_dsl"] = dsl
            store["use_llm"] = True
            
            print(f"âœ… LLMç”Ÿæˆå®Œäº†: Prior={len(dsl['prior']['terms'])}é …, Reward={dsl['reward']['formula']}")
            
        except Exception as e:
            print(f"âš ï¸ LLMç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(500, f"LLMç”Ÿæˆå¤±æ•—: {str(e)}")
    else:
        store["use_llm"] = False

    # å­¦ç¿’ã‚¿ã‚¹ã‚¯ï¼ˆåŒãƒ—ãƒ­ã‚»ã‚¹/åŒã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹
    asyncio.create_task(_train_loop(req.episode_id))
    return {"started": True, "use_llm": req.use_llm}

# ------- å­¦ç¿’åœæ­¢ -------

@app.post("/stop")
async def stop_train(episode_id: str):
    """
    å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’åœæ­¢ã•ã›ã‚‹ã€‚
    - should_stop ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹ã“ã¨ã§ã€_train_loop ãŒæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§åœæ­¢ã™ã‚‹ã€‚
    """
    if episode_id not in EPISODES:
        raise HTTPException(404, "episode not found")
    
    EPISODES[episode_id]["should_stop"] = True
    return {"stopped": True}

# ------- SSE ã‚¹ãƒˆãƒªãƒ¼ãƒ  -------

@app.get("/stream")
async def stream(request: Request, episode_id: str):
    """
    SSE (Server-Sent Events) ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡ã€‚
    - /train ã§èµ·å‹•ã—ãŸå­¦ç¿’ãƒ«ãƒ¼ãƒ—ãŒ metrics.timeline ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç©ã‚€
    - ã“ã“ã§ã¯ãã‚Œã‚’é †æ¬¡ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸é€ã‚‹ï¼ˆå¿ƒæ‹ï¼‹å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰
    """
    if episode_id not in EPISODES:
        raise HTTPException(404, "episode not found")

    async def event_gen():
        last_idx = 0
        last_cleanup = 0
        while True:
            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­ã‚’æ¤œçŸ¥ã—ãŸã‚‰çµ‚äº†
            if await request.is_disconnected():
                break
            store = EPISODES.get(episode_id)
            if not store:
                break
            tl = store["metrics"]["timeline"]
            # æœªé€ä¿¡ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’é †ã«é€ä¿¡
            while last_idx < len(tl):
                ev = tl[last_idx]; last_idx += 1
                yield f"data: {json.dumps(ev)}\n\n"
            
            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢: é€ä¿¡æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã‚’å®šæœŸçš„ã«å‰Šé™¤ï¼ˆ1000ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ï¼‰
            if last_idx - last_cleanup > 1000:
                # é€ä¿¡æ¸ˆã¿ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‰Šé™¤ï¼ˆæœ€æ–°200ä»¶ã¯ä¿æŒï¼‰
                keep_from = max(0, last_idx - 200)
                store["metrics"]["timeline"] = tl[keep_from:]
                last_idx = len(store["metrics"]["timeline"])
                last_cleanup = last_idx
            
            await asyncio.sleep(0.05)  # ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”ï¼ˆCPUéè² è·é˜²æ­¢ï¼‰

    return StreamingResponse(
        event_gen(),
        media_type="text/event-stream",
        headers={"Cache-Control":"no-cache"}
    )

# ------- å†…éƒ¨: å­¦ç¿’ãƒ«ãƒ¼ãƒ—æœ¬ä½“ -------

async def _train_loop(ep_id: str):
    """
    å­¦ç¿’ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆéåŒæœŸï¼‰ã€‚
    - å„ã‚¹ãƒ†ãƒƒãƒ—ã§:
        * è¡Œå‹•é¸æŠ â†’ ç’°å¢ƒæ›´æ–°
        * M1/M2 è¨ˆç®—ã€æˆåŠŸåˆ¤å®šï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬ï¼‰
        * ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡æ ¼ç´ â†’ æ›´æ–°ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œï¼‰
        * SSEç”¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’ metrics.timeline ã«push
    - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã« metrics.json / final_shape.png ã‚’ä¿å­˜
    """
    store = EPISODES[ep_id]
    env: SwarmEnv = store["env"]
    maddpg: MADDPGSystem = store["rl"]
    cfg = store["cfg"]
    E = store["episodes_total"]; T = store["episode_len"]
    
    # ---- SSE ã‚¤ãƒ™ãƒ³ãƒˆ: ç’°å¢ƒè¨­å®šã‚’æœ€åˆã«é€ä¿¡ ----
    store["metrics"]["timeline"].append({
        "type": "env_config",
        "shape": cfg.shape,
        "n_robot": cfg.n_robot,
        "r_sense": cfg.r_sense,
        "r_avoid": cfg.r_avoid,
        "n_hn": cfg.nhn,
        "n_hc": cfg.nhc,
        "grid_size": env.grid_size,
        "l_cell": env.lc,
        "use_llm": store.get("use_llm", False),
    })
    
    global_step = 0  # å…¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’é€šã˜ãŸç´¯ç©ã‚¹ãƒ†ãƒƒãƒ—æ•°

    for ep in range(E):
        # åœæ­¢ãƒ•ãƒ©ã‚°ãƒã‚§ãƒƒã‚¯
        if store.get("should_stop", False):
            print(f"â¹ï¸ Training stopped by user request (ep_id={ep_id})")
            break
            
        obs = env.reset()
        episode_stopped = False  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å†…ã§ã®åœæ­¢ãƒ•ãƒ©ã‚°
        
        for t in range(T):
            # åœæ­¢ãƒ•ãƒ©ã‚°ãƒã‚§ãƒƒã‚¯
            if store.get("should_stop", False):
                print(f"â¹ï¸ Training stopped by user request (ep_id={ep_id})")
                episode_stopped = True
                break
            
            # è¡Œå‹•ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†ï¼‰
            # LLM Prior Policyã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€çŠ¶æ…‹è¾æ›¸ã‚’æ¸¡ã™
            state_dicts = None
            if store.get("use_llm", False):
                state_dicts = env.get_state_dicts()
            
            acts = maddpg.act(obs, deterministic=False, state_dicts=state_dicts)

            # ç’°å¢ƒ1ã‚¹ãƒ†ãƒƒãƒ—
            nobs, col_pairs = env.step(acts)

            # æŒ‡æ¨™è¨ˆæ¸¬ï¼ˆCoverage/M1 ã¨ Uniformity/M2ï¼‰
            M1 = coverage_m1(env.mask, env.p, cfg.r_avoid)
            M2 = uniformity_m2(env.p, env.mask)

            # å ±é…¬è¨ˆç®—: LLMç”Ÿæˆã®Reward Functionã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ã€ãã†ã§ãªã‘ã‚Œã°ã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬
            if store.get("use_llm", False) and maddpg.reward_fn is not None:
                try:
                    # è¡çªæ•°ã‚’è¨ˆç®—
                    n_collisions = len(col_pairs)
                    # LLMç”Ÿæˆã®Reward Functionã§å ±é…¬ã‚’è¨ˆç®—
                    rew_scalar = maddpg.reward_fn({
                        "coverage": float(M1),
                        "uniformity": float(M2),
                        "collisions": float(n_collisions)
                    })
                except Exception as e:
                    print(f"âš ï¸ Reward function error: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬
                    rew_scalar = 1.0 if (M1 > 0.8 and M2 < 0.2) else 0.0
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬ï¼ˆè«–æ–‡ã®æœ€çµ‚åˆ¤å®šã«æº–æ‹ ã—ãŸç°¡ç•¥å½¢ï¼‰
                rew_scalar = 1.0 if (M1 > 0.8 and M2 < 0.2) else 0.0
            
            # æˆåŠŸåˆ¤å®šï¼ˆæ—©æœŸçµ‚äº†ç”¨ï¼‰
            done = 1.0 if (M1 > 0.8 and M2 < 0.2) else 0.0

            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åŒä¸€å ±é…¬ï¼ˆå”èª¿ã‚¿ã‚¹ã‚¯ã®æœ€å°å®Ÿè£…ï¼‰
            for i in range(cfg.n_robot):
                maddpg.buffers[i].push(
                    obs[i], acts[i],
                    np.array([rew_scalar], dtype=np.float32),
                    nobs[i], np.array([done], dtype=np.float32)
                )

            # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
            upd = maddpg.step_update()

            # ---- SSE ã‚¤ãƒ™ãƒ³ãƒˆ: tickï¼ˆæ¯ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ ----
            store["metrics"]["timeline"].append({
                "type": "tick",
                "episode": ep,
                "step": t,
                "global_step": global_step,
                "positions": env.p.tolist(),
                "velocities": env.v.tolist(),
                "collisions": col_pairs,
            })
            # ---- SSE ã‚¤ãƒ™ãƒ³ãƒˆ: metrics_updateï¼ˆé–“å¼•ãé€ä¿¡: 10ã‚¹ãƒ†ãƒƒãƒ—æ¯ï¼‰----
            if t % 10 == 0:
                store["metrics"]["timeline"].append({
                    "type": "metrics_update",
                    "episode": ep,
                    "step": t,
                    "global_step": global_step,
                    "M1": M1, "M2": M2,
                    **({"loss_actor": upd["loss_actor"], "loss_critic": upd["loss_critic"]} if upd else {})
                })

            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
            global_step += 1

            # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«åˆ¶å¾¡ã‚’è¿”ã™ï¼ˆSSEé€ä¿¡ã‚’å¯èƒ½ã«ã™ã‚‹ï¼‰
            await asyncio.sleep(0)

            obs = nobs
            if done == 1.0:
                # æˆåŠŸåˆ¤å®šã§æ—©æœŸçµ‚äº†ï¼ˆåæŸæ‰±ã„ï¼‰
                break

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹åœæ­¢ã®å ´åˆã¯ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ã‚‰ãšã«çµ‚äº†
        if episode_stopped:
            break

        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†:  SSE é€šçŸ¥
        store["metrics"]["timeline"].append({
            "type": "episode_end",
            "episode_id": ep_id,
            "episode": ep,
            "step": t,  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å†…ã®æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—
            "global_step": global_step - 1,  # æœ€å¾Œã«ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã—ã¦ã„ã‚‹ã®ã§-1
            "M1": float(M1),
            "M2": float(M2),
            "final_positions": env.p.tolist(),  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã®æœ€çµ‚ä½ç½®
            "final_velocities": env.v.tolist(),  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã®æœ€çµ‚é€Ÿåº¦
        })
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–“ã§ã‚‚ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«åˆ¶å¾¡ã‚’è¿”ã™
        await asyncio.sleep(0)
