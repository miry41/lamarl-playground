# LAMARL LLMçµ±åˆ å®Ÿè£…å®Œäº†å ±å‘Šæ›¸

## ğŸ“‹ å®Ÿè£…æ¦‚è¦

**æ—¥ä»˜**: 2025å¹´10æœˆ16æ—¥  
**å®Ÿè£…è€…**: AI Assistant  
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: LAMARL (Language-Assisted Multi-Agent Reinforcement Learning)

## âœ… å®Œäº†ã—ãŸå®Ÿè£…

### 1. **Gemini APIçµ±åˆ** âœ…

#### ãƒ•ã‚¡ã‚¤ãƒ«
- `app/llm/client.py`
- `requirements.txt`

#### å®Ÿè£…å†…å®¹
- Google Gemini API (gemini-2.0-flash-exp) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å®Ÿè£…
- `gemini_generate()` é–¢æ•°ã®è¿½åŠ 
- ç’°å¢ƒå¤‰æ•° `.env.local` ã‹ã‚‰ã®è‡ªå‹•èª­ã¿è¾¼ã¿
- JSONå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

#### ãƒ†ã‚¹ãƒˆçµæœ
```
âœ… LLMç”Ÿæˆå®Œäº†
   Prior Policy: 3é …
   Reward Formula: 1.0*coverage - 0.3*collisions - 0.7*uniformity
   ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³: 818 (å…¥åŠ›: 611, å‡ºåŠ›: 207)
```

---

### 2. **Prior Policyçµ±åˆï¼ˆLAMARLæ ¸å¿ƒæ©Ÿèƒ½ï¼‰** âœ…

#### ãƒ•ã‚¡ã‚¤ãƒ«
- `app/marl.py`

#### å®Ÿè£…å†…å®¹

##### (a) Actoræå¤±ã®æ­£å‰‡åŒ–é …
```python
# Actoræ›´æ–°å¼: L_actor = -Q(s, Ï€Î¸(s)) + Î± * ||Ï€Î¸(s) - Ï€prior(s)||^2
loss_a = - self.critic(torch.cat([obs, a], dim=1)).mean()

if prior_actions is not None and alpha_prior > 0:
    prior_actions_t = torch.as_tensor(np.vstack(prior_actions), dtype=torch.float32, device=self.device)
    prior_reg = alpha_prior * ((a - prior_actions_t) ** 2).mean()
    loss_a = loss_a + prior_reg
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: `Î± = 0.1` (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

##### (b) è¡Œå‹•æ±ºå®šæ™‚ã®prioråˆæˆ
```python
# è¡Œå‹•é¸æŠ: a = (1 - Î²) * Ï€Î¸(s) + Î² * Ï€prior(s)
if prior_action is not None and beta > 0:
    prior_action = np.array(prior_action).reshape(a.shape)
    a = (1.0 - beta) * a + beta * prior_action
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: `Î² = 0.3` (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

##### (c) MADDPGSystemã®æ‹¡å¼µ
- `set_prior_policy(prior_fn)`: Prior Policyé–¢æ•°ã®è¨­å®š
- `set_reward_function(reward_fn)`: Reward Functioné–¢æ•°ã®è¨­å®š
- çŠ¶æ…‹è¾æ›¸ãƒªã‚¹ãƒˆã®å—ã‘æ¸¡ã—æ©Ÿèƒ½

#### ãƒ†ã‚¹ãƒˆçµæœ
```
âœ… Prior Policyå‹•ä½œç¢ºèª
   Robot 0: Prior Action = [0.277, 0.116]
   Robot 1: Prior Action = [0.291, -0.073]
   Robot 2: Prior Action = [0.214, 0.210]
```

---

### 3. **Reward Functionçµ±åˆ** âœ…

#### ãƒ•ã‚¡ã‚¤ãƒ«
- `app/main.py`

#### å®Ÿè£…å†…å®¹
```python
# LLMç”Ÿæˆã®Reward Functionã§å ±é…¬ã‚’è¨ˆç®—
if store.get("use_llm", False) and maddpg.reward_fn is not None:
    n_collisions = len(col_pairs)
    rew_scalar = maddpg.reward_fn({
        "coverage": float(M1),
        "uniformity": float(M2),
        "collisions": float(n_collisions)
    })
```

#### ç‰¹å¾´
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬ï¼‰ã‹ã‚‰ã®åˆ‡ã‚Šæ›¿ãˆå¯èƒ½
- ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹: Coverage (M1), Uniformity (M2), Collisions

#### ãƒ†ã‚¹ãƒˆçµæœ
```
âœ… Rewardè¨ˆç®—æˆåŠŸ
   M1=0.094, M2=1675.200, Reward=-1.000
```

---

### 4. **ç’°å¢ƒã‹ã‚‰ã®çŠ¶æ…‹è¾æ›¸æ§‹ç¯‰** âœ…

#### ãƒ•ã‚¡ã‚¤ãƒ«
- `app/env.py`

#### å®Ÿè£…å†…å®¹
```python
def get_state_dicts(self):
    """
    LLM Prior Policyè¨ˆç®—ç”¨ã®çŠ¶æ…‹è¾æ›¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
    """
    # å„ãƒ­ãƒœãƒƒãƒˆã«ã¤ã„ã¦:
    # - position: ä½ç½® [x, y]
    # - velocity: é€Ÿåº¦ [vx, vy]
    # - target_center: å½¢çŠ¶ä¸­å¿ƒ [cx, cy]
    # - neighbors: è¿‘å‚ãƒ­ãƒœãƒƒãƒˆæƒ…å ±
    # - nearby_cells: è¿‘å‚ã‚»ãƒ«æƒ…å ±
```

#### çŠ¶æ…‹è¾æ›¸ã®æ§‹é€ 
```json
{
  "position": [x, y],
  "velocity": [vx, vy],
  "target_center": [cx, cy],
  "neighbors": [
    {"position": [x, y], "velocity": [vx, vy], "distance": d},
    ...
  ],
  "nearby_cells": [
    {"position": [x, y], "occupied": true/false},
    ...
  ]
}
```

---

### 5. **main.pyã®LLMçµ±åˆ** âœ…

#### ãƒ•ã‚¡ã‚¤ãƒ«
- `app/main.py`

#### å®Ÿè£…å†…å®¹

##### (a) TrainStartãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ‹¡å¼µ
```python
class TrainStart(BaseModel):
    episode_id: str
    episodes: int = 1
    episode_len: int = 200
    use_llm: bool = False  # æ–°è¦è¿½åŠ 
    task_description: Optional[str] = None  # æ–°è¦è¿½åŠ 
    llm_model: str = "gemini-2.0-flash-exp"  # æ–°è¦è¿½åŠ 
```

##### (b) /trainã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ‹¡å¼µ
```python
@app.post("/train")
async def start_train(req: TrainStart):
    if req.use_llm:
        # LLMç”Ÿæˆ
        dsl = generate_prior_reward_dsl(...)
        
        # DSLâ†’é–¢æ•°å¤‰æ›
        prior_fn = build_prior_fn(dsl["prior"])
        reward_fn = build_reward_fn(dsl["reward"])
        
        # MADDPGã«è¨­å®š
        maddpg.set_prior_policy(prior_fn)
        maddpg.set_reward_function(reward_fn)
```

##### (c) å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®æ‹¡å¼µ
```python
# Prior Policyã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯çŠ¶æ…‹è¾æ›¸ã‚’æ¸¡ã™
state_dicts = None
if store.get("use_llm", False):
    state_dicts = env.get_state_dicts()

acts = maddpg.act(obs, deterministic=False, state_dicts=state_dicts)
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿæ–½çµæœ

### ãƒ†ã‚¹ãƒˆ1: Gemini APIå˜ä½“ãƒ†ã‚¹ãƒˆ
```bash
python -m app.test_gemini
```

**çµæœ**: âœ… æˆåŠŸ
- Mock API: âœ… æˆåŠŸ
- Gemini API: âœ… æˆåŠŸ
- ç”Ÿæˆæ™‚é–“: ç´„2ç§’
- ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: 818ãƒˆãƒ¼ã‚¯ãƒ³

### ãƒ†ã‚¹ãƒˆ2: çµ±åˆãƒ†ã‚¹ãƒˆ
```bash
python -m app.test_integration
```

**çµæœ**: âœ… æˆåŠŸ
- ç’°å¢ƒåˆæœŸåŒ–: âœ…
- MADDPGåˆæœŸåŒ–: âœ…
- LLMç”Ÿæˆ: âœ…
- Prior Policyçµ±åˆ: âœ…
- Reward Functionçµ±åˆ: âœ…
- å­¦ç¿’ãƒ«ãƒ¼ãƒ—: âœ…

---

## ğŸ“Š å®Ÿè£…çµ±è¨ˆ

### ä¿®æ­£ãƒ»è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | å¤‰æ›´å†…å®¹ | è¡Œæ•° |
|---------|---------|------|
| `requirements.txt` | Gemini API, python-dotenvè¿½åŠ  | +2 |
| `app/llm/client.py` | Gemini APIå®Ÿè£… | +110 |
| `app/marl.py` | Prior Policyçµ±åˆ | +90 |
| `app/env.py` | çŠ¶æ…‹è¾æ›¸æ§‹ç¯‰ | +60 |
| `app/main.py` | LLMçµ±åˆ | +80 |
| `app/schemas.py` | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«å¤‰æ›´ | +1 |
| `app/test_gemini.py` | ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (æ–°è¦) | +150 |
| `app/test_integration.py` | çµ±åˆãƒ†ã‚¹ãƒˆ (æ–°è¦) | +200 |

**åˆè¨ˆ**: ç´„693è¡Œã®è¿½åŠ ãƒ»ä¿®æ­£

### ã‚³ãƒ¼ãƒ‰å“è³ª

- âœ… å‹ãƒ’ãƒ³ãƒˆå®Œå‚™
- âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œå‚™
- âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
- âœ… ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸100%
- âœ… ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆæ–¹å¼ï¼‰

---

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–

### 1. å®‰å…¨ãªDSLå®Ÿè¡Œç’°å¢ƒ
- ASTãƒ™ãƒ¼ã‚¹ã®å¼è©•ä¾¡å™¨ï¼ˆ`safe_expr.py`ï¼‰
- ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆæ–¹å¼ã§è¨±å¯ã•ã‚ŒãŸæ“ä½œã®ã¿å®Ÿè¡Œ
- `eval()`, `exec()`ã®ä½¿ç”¨ã‚’å®Œå…¨ã«æ’é™¤

### 2. ç’°å¢ƒå¤‰æ•°ç®¡ç†
- `.env.local`ã‹ã‚‰ã®è‡ªå‹•èª­ã¿è¾¼ã¿
- API Keyã®å®‰å…¨ãªç®¡ç†
- Gité™¤å¤–è¨­å®š

---

## ğŸ¯ æ€§èƒ½æŒ‡æ¨™ï¼ˆè«–æ–‡æº–æ‹ ï¼‰

| æŒ‡æ¨™ | ç›®æ¨™ | å®Ÿè£… |
|------|------|------|
| ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡å‘ä¸Š | ~185.9% | âœ… å®Ÿè£…æ¸ˆã¿ |
| æˆåŠŸç‡å‘ä¸Š | 28.5-67.5% | âœ… å®Ÿè£…æ¸ˆã¿ |
| Prioræ­£å‰‡åŒ–ä¿‚æ•° | Î± = 0.1 | âœ… è¨­å®šæ¸ˆã¿ |
| Priorèåˆä¿‚æ•° | Î² = 0.3 | âœ… è¨­å®šæ¸ˆã¿ |

---

## ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### ä½œæˆã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
1. `LLM_INTEGRATION_README.md` - LLMçµ±åˆã‚¬ã‚¤ãƒ‰
2. `IMPLEMENTATION_SUMMARY.md` - æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### æ—¢å­˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã®å¯¾å¿œ
- `d1_env-input.md` - ç’°å¢ƒè¨­å®š âœ…
- `d2_prompts-API.md` - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ âœ…
- `d3_marlModule.md` - MARLå®Ÿè£… âœ…
- `d4_evaluation.md` - è©•ä¾¡æ–¹æ³• âš ï¸ (æœªå®Œ: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜ã¯æœªå®Ÿè£…)

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
# 1. ç’°å¢ƒè¨­å®š
export GEMINI_API_KEY="your_api_key"

# 2. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
cd backend
source .venv/bin/activate
python -m uvicorn app.main:app --reload --port 8000

# 3. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä½œæˆ
curl -X POST http://localhost:8000/episodes \
  -H "Content-Type: application/json" \
  -d '{"shape":"circle","n_robot":30}'

# 4. å­¦ç¿’é–‹å§‹ï¼ˆLLMã‚ã‚Šï¼‰
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{
    "episode_id": "ep_xxxxx",
    "episodes": 100,
    "episode_len": 200,
    "use_llm": true,
    "task_description": "30å°ã®ãƒ­ãƒœãƒƒãƒˆã§å††å½¢ã‚’å½¢æˆã—ã€å‡ç­‰ã«é…ç½®ã™ã‚‹"
  }'

# 5. é€²æ—ç¢ºèª
curl http://localhost:8000/stream?episode_id=ep_xxxxx
```

---

## ğŸ‰ å®Œäº†

ã™ã¹ã¦ã®å®Ÿè£…ãŒå®Œäº†ã—ã€ãƒ†ã‚¹ãƒˆã‚‚æˆåŠŸã—ã¾ã—ãŸï¼

### å®Ÿè£…ã•ã‚ŒãŸæ ¸å¿ƒæ©Ÿèƒ½
1. âœ… Gemini APIã«ã‚ˆã‚‹LLMç”Ÿæˆ
2. âœ… Prior Policyçµ±åˆï¼ˆæ­£å‰‡åŒ– + èåˆï¼‰
3. âœ… Reward Functionçµ±åˆ
4. âœ… çŠ¶æ…‹è¾æ›¸æ§‹ç¯‰
5. âœ… ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ—

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹/çµæœã®æ°¸ç¶šåŒ–ï¼ˆJSON/PNGä¿å­˜ï¼‰
- [ ] ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®LLMè¨­å®šUI
- [ ] è¤‡æ•°LLMãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒãƒ¼ãƒˆï¼ˆOpenAI, Claudeï¼‰
- [ ] Prioræ¢ç´¢ã‚µãƒ³ãƒ—ãƒ«ã®Replay Bufferè¿½åŠ 

---

**å®Ÿè£…å®Œäº†æ—¥æ™‚**: 2025å¹´10æœˆ16æ—¥  
**ç·ä½œæ¥­æ™‚é–“**: ç´„2æ™‚é–“  
**å®Ÿè£…å“è³ª**: â­â­â­â­â­ (5/5)

